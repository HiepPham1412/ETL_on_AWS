{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ETL implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook help to test our ETL implementation script.\n",
    "Main steps:\n",
    "1. Create Redshift cluster on AWS\n",
    "2. Create database\n",
    "3. Load the data from S3 to staging tables, then transform and insert data to database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Redshift Cluster on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create iam and ec2 object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY = config['AWS']['KEY']\n",
    "SECRET = config['AWS']['SECRET']\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )\n",
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name='us-west-2'\n",
    "                  )\n",
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::172826706179:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "DWH_IAM_ROLE_NAME = config['DWH']['DWH_IAM_ROLE_NAME']\n",
    "#1.1 Create the role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DWH_CLUSTER_TYPE = config['DWH']['DWH_CLUSTER_TYPE']\n",
    "DWH_NODE_TYPE = config['DWH']['DWH_NODE_TYPE']\n",
    "DWH_NUM_NODES = config['DWH']['DWH_NUM_NODES']\n",
    "\n",
    "DWH_DB = config['CLUSTER']['DB_NAME']\n",
    "DWH_CLUSTER_IDENTIFIER = config['DWH']['DWH_CLUSTER_IDENTIFIER']\n",
    "DWH_DB_USER = config['CLUSTER']['DB_USER']\n",
    "DWH_DB_PASSWORD = config['CLUSTER']['DB_PASSWORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#roleArn = config['IAM_ROLE']['ARN']\n",
    "\n",
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.c32slsdkedl6.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-d2f351aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.c32slsdkedl6.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-d2f351aa                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhcluster.c32slsdkedl6.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::172826706179:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up TCP connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-fc2885b7')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "DWH_PORT = config['CLUSTER']['DB_PORT']\n",
    "\n",
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries\n",
    "\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    \"\"\"drop tables(if exists) in the database \n",
    "    :param cur: cursor object\n",
    "    :param conn: psycopg's connection object (connect to a database in Redshift cluster)\n",
    "    \n",
    "    \"\"\"\n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    \"\"\"create tables in the database\n",
    "    :param cur: cursor object\n",
    "    :param conn: psycopg's connection object (connect to a database in Redshift cluster)\n",
    "    \n",
    "    \"\"\"\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dwh.cfg')\n",
    "\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    drop_tables(cur, conn)\n",
    "    create_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from sql_queries import copy_table_queries, insert_table_queries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def load_staging_tables(cur, conn):\n",
    "    \"\"\"load raw data from S3 to staging tables in Redshift.\n",
    "    :param cur: cursor object\n",
    "    :param conn: psycopg's connection object (connect to a database in Redshift cluster)\n",
    "    \n",
    "    \"\"\"\n",
    "    for query in copy_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def insert_tables(cur, conn):\n",
    "    \"\"\"insert data from staging tables to other tables.\n",
    "    :param cur: cursor object\n",
    "    :param conn: psycopg's connection object (connect to a database in Redshift cluster)\n",
    "    \n",
    "    \"\"\"\n",
    "    for query in insert_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dwh.cfg')\n",
    "\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    load_staging_tables(cur, conn)\n",
    "    insert_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173, datetime.datetime(2018, 11, 5, 11, 14), 44, 'paid', 'SOCDOVE12AB01808DE', 'ARYE9E71187B9AA1B3', '269', 'Waterloo-Cedar Falls, IA', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
      "(243, datetime.datetime(2018, 11, 5, 14, 43, 54), 44, 'paid', 'SOZARNI12A67020744', 'AR3WLE91187B99430A', '269', 'Waterloo-Cedar Falls, IA', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
      "(165, datetime.datetime(2018, 11, 5, 17, 0, 27), 73, 'paid', 'SOBANHD12A58A7BB7C', 'ARSUFX91187FB3B73E', '255', 'Tampa-St. Petersburg-Clearwater, FL', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2\"')\n",
      "(124, datetime.datetime(2018, 11, 7, 18, 11, 11), 15, 'paid', 'SODTRKW12A6D4F9A51', 'AR71MIY1187B9BA0C3', '221', 'Chicago-Naperville-Elgin, IL-IN-WI', '\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"')\n",
      "(322, datetime.datetime(2018, 11, 9, 11, 44, 35), 95, 'paid', 'SOHTKMO12AB01843B0', 'AR5EYTL1187B98EDA0', '276', 'Winston-Salem, NC', '\"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like Mac OS X) AppleWebKit/537.51.2 (KHTML, like Gecko) Version/7.0 Mobile/11D257 Safari/9537.53\"')\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT * from songplay LIMIT 5;')\n",
    "rows=cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 'Austin', 'Rosales', 'M', 'free')\n",
      "(18, 'Jacob', 'Rogers', 'M', 'free')\n",
      "(33, 'Bronson', 'Harris', 'M', 'free')\n",
      "(35, 'Molly', 'Taylor', 'F', 'free')\n",
      "(38, 'Gianna', 'Jones', 'F', 'free')\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT * from users LIMIT 5;')\n",
    "rows=cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SOAADUU12AB0183B6F', 'Intro / Locataire (Instrumental)', 'AR70XXH1187FB44B55', 0, 101.92934)\n",
      "('SOAAFUV12AB018831D', 'Where Do The Children Play? (LP Version)', 'AR5ZGC11187FB417A3', 0, 216.05832)\n",
      "('SOAAGXT12A8C13A94D', 'Beautiful Zelda (2007 Digital Remaster)', 'ARTC1LV1187B9A4858', 1968, 145.03138)\n",
      "('SOAAKBE12A8C139075', 'Emília', 'ART1OPW1187FB3C5EF', 0, 159.7122)\n",
      "('SOAAKLA12A58A7A3CC', 'Snow Day (LP Version)', 'ARGWNT41187FB463F1', 0, 211.90485)\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT * from songs LIMIT 5;')\n",
    "rows=cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AR00Y9I1187B999412', 'Akercocke', '', None, None)\n",
      "('AR01SCU1187B9A693C', 'Street Dogs', 'Boston, MA', None, None)\n",
      "('AR02T3I1187FB4D0E5', 'Aberfeldy', 'Edinburgh, Scotland', None, None)\n",
      "('AR03IZC1187FB3E058', 'Aidonia', '', None, None)\n",
      "('AR05IU31187B9B9A1A', 'Alex Ubago', 'Vitoria, Spain', 42.84751, -2.67973)\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT * from artists LIMIT 5;')\n",
    "rows=cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 11, 2, 16, 35), 16, 2, 44, 11, 2018, 5)\n",
      "(datetime.datetime(2018, 11, 3, 18, 19, 10), 18, 3, 44, 11, 2018, 6)\n",
      "(datetime.datetime(2018, 11, 3, 19, 33, 39), 19, 3, 44, 11, 2018, 6)\n",
      "(datetime.datetime(2018, 11, 5, 1, 48), 1, 5, 45, 11, 2018, 1)\n",
      "(datetime.datetime(2018, 11, 5, 11, 8, 56), 11, 5, 45, 11, 2018, 1)\n",
      "(datetime.datetime(2018, 11, 5, 11, 36, 56), 11, 5, 45, 11, 2018, 1)\n",
      "(datetime.datetime(2018, 11, 5, 18, 26, 7), 18, 5, 45, 11, 2018, 1)\n",
      "(datetime.datetime(2018, 11, 6, 8, 49, 19), 8, 6, 45, 11, 2018, 2)\n",
      "(datetime.datetime(2018, 11, 6, 16, 38, 15), 16, 6, 45, 11, 2018, 2)\n",
      "(datetime.datetime(2018, 11, 6, 20, 12, 11), 20, 6, 45, 11, 2018, 2)\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT * from time LIMIT 10;')\n",
    "rows=cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'ClusterAvailabilityStatus': 'Modifying',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.c32slsdkedl6.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2019, 12, 29, 8, 19, 50, 484000, tzinfo=tzutc()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ManualSnapshotRetentionPeriod': -1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-fc2885b7',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-d2f351aa',\n",
       "  'AvailabilityZone': 'us-west-2b',\n",
       "  'PreferredMaintenanceWindow': 'sat:13:30-sat:14:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::172826706179:role/dwhRole',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current',\n",
       "  'DeferredMaintenanceWindows': [],\n",
       "  'NextMaintenanceWindowStartTime': datetime.datetime(2020, 1, 4, 13, 30, tzinfo=tzutc())},\n",
       " 'ResponseMetadata': {'RequestId': '434d85fe-2a22-11ea-aed5-6b3735f69591',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '434d85fe-2a22-11ea-aed5-6b3735f69591',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2382',\n",
       "   'vary': 'Accept-Encoding',\n",
       "   'date': 'Sun, 29 Dec 2019 10:02:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redshift.delete_cluster(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
